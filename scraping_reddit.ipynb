{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-19T12:23:20.121809027Z",
     "start_time": "2023-05-19T12:23:19.900652921Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('keys.txt', 'r') as file:\n",
    "    # Read the entire contents of the file into a variable\n",
    "    file_contents = file.read()\n",
    "    keys = file_contents.split('\\n')\n",
    "\n",
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=keys[0],\n",
    "    client_secret=keys[1],\n",
    "    user_agent=keys[2],\n",
    "    username=keys[3],\n",
    "    password=keys[4]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wash sale - advice needed\n",
      "Volume tickers in play\n",
      "Every regional bank Chief Risk Officer in 2023 :\n",
      "Daily Discussion Thread for May 19, 2023\n",
      "US Treasury's cash balance falls to $68.3bn, lowest since 2021.\n",
      "Corporate wants you to find the difference between these two pictures\n",
      "Minor win before my soon-to-be McDonalds job orientation\n",
      "Rate hike expectations just rose, JPow to come out today to shock the markets?\n",
      "FED rates are going down this fall\n",
      "The end of the world is bullish.\n"
     ]
    }
   ],
   "source": [
    "subreddit = reddit.subreddit('wallstreetbets')\n",
    "for post in subreddit.new(limit=10):\n",
    "    print(post.title)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T12:23:22.234267144Z",
     "start_time": "2023-05-19T12:23:20.126013594Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T12:23:23.612797204Z",
     "start_time": "2023-05-19T12:23:22.234963699Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wash wash VERB VB compound\n",
      "sale sale NOUN NN compound\n",
      "- - PUNCT HYPH punct\n",
      "advice advice NOUN NN nsubj\n",
      "needed need VERB VBD ROOT\n",
      "Volume volume NOUN NN nsubj\n",
      "tickers ticker VERB VBZ ROOT\n",
      "in in ADP IN prep\n",
      "play play NOUN NN pobj\n",
      "Every every DET DT det\n",
      "regional regional ADJ JJ amod\n",
      "bank bank NOUN NN compound\n",
      "Chief Chief PROPN NNP compound\n",
      "Risk Risk PROPN NNP compound\n",
      "Officer Officer PROPN NNP ROOT\n",
      "in in ADP IN prep\n",
      "2023 2023 NUM CD pobj\n",
      ": : PUNCT : punct\n",
      "Daily Daily PROPN NNP compound\n",
      "Discussion Discussion PROPN NNP compound\n",
      "Thread Thread PROPN NNP ROOT\n",
      "for for ADP IN prep\n",
      "May May PROPN NNP pobj\n",
      "19 19 NUM CD nummod\n",
      ", , PUNCT , punct\n",
      "2023 2023 NUM CD nummod\n",
      "US US PROPN NNP compound\n",
      "Treasury Treasury PROPN NNP poss\n",
      "'s 's PART POS case\n",
      "cash cash NOUN NN compound\n",
      "balance balance NOUN NN nsubj\n",
      "falls fall VERB VBZ ROOT\n",
      "to to ADP IN prep\n",
      "$ $ SYM $ nmod\n",
      "68.3bn 68.3bn NUM CD pobj\n",
      ", , PUNCT , punct\n",
      "lowest low ADJ JJS conj\n",
      "since since SCONJ IN prep\n",
      "2021 2021 NUM CD pobj\n",
      ". . PUNCT . punct\n",
      "Corporate corporate ADJ JJ nsubj\n",
      "wants want VERB VBZ ROOT\n",
      "you you PRON PRP nsubj\n",
      "to to PART TO aux\n",
      "find find VERB VB ccomp\n",
      "the the DET DT det\n",
      "difference difference NOUN NN dobj\n",
      "between between ADP IN prep\n",
      "these these DET DT det\n",
      "two two NUM CD nummod\n",
      "pictures picture NOUN NNS pobj\n",
      "Minor minor ADJ JJ amod\n",
      "win win NOUN NN ROOT\n",
      "before before ADP IN prep\n",
      "my my PRON PRP$ poss\n",
      "soon soon ADV RB advmod\n",
      "- - PUNCT HYPH punct\n",
      "to to PART TO aux\n",
      "- - PUNCT HYPH punct\n",
      "be be AUX VB nmod\n",
      "McDonalds McDonalds PROPN NNP compound\n",
      "job job NOUN NN compound\n",
      "orientation orientation NOUN NN pobj\n",
      "Rate rate NOUN NN compound\n",
      "hike hike NOUN NN compound\n",
      "expectations expectation NOUN NNS nsubj\n",
      "just just ADV RB advmod\n",
      "rose rise VERB VBD ROOT\n",
      ", , PUNCT , punct\n",
      "JPow jpow PRON PRP npadvmod\n",
      "to to PART TO aux\n",
      "come come VERB VB advcl\n",
      "out out ADP RP prt\n",
      "today today NOUN NN npadvmod\n",
      "to to PART TO aux\n",
      "shock shock VERB VB advcl\n",
      "the the DET DT det\n",
      "markets market NOUN NNS dobj\n",
      "? ? PUNCT . punct\n",
      "FED FED PROPN NNP compound\n",
      "rates rate NOUN NNS nsubj\n",
      "are be AUX VBP aux\n",
      "going go VERB VBG ROOT\n",
      "down down ADP IN prep\n",
      "this this DET DT det\n",
      "fall fall NOUN NN npadvmod\n",
      "The the DET DT det\n",
      "end end NOUN NN nsubj\n",
      "of of ADP IN prep\n",
      "the the DET DT det\n",
      "world world NOUN NN pobj\n",
      "is be AUX VBZ ROOT\n",
      "bullish bullish ADJ JJ acomp\n",
      ". . PUNCT . punct\n"
     ]
    }
   ],
   "source": [
    "for post in subreddit.new(limit=10):\n",
    "    doc = nlp(post.title)\n",
    "    for token in doc:\n",
    "        print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T12:23:24.148390941Z",
     "start_time": "2023-05-19T12:23:23.611619392Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def extract_stock_information(text):\n",
    "    doc = nlp(text)\n",
    "    entities = []\n",
    "    sentiments = []\n",
    "\n",
    "    for entity in doc.ents:\n",
    "        if entity.label_ == \"ORG\" and \"tesla\" in entity.text.lower():\n",
    "            entities.append(entity.text)\n",
    "\n",
    "    for sentence in doc.sents:\n",
    "        sentiment = sentence.sentiment\n",
    "        sentiments.append(sentiment)\n",
    "\n",
    "    return entities, sentiments"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T12:23:24.155176177Z",
     "start_time": "2023-05-19T12:23:24.150547610Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "for post in subreddit.new(limit=10):\n",
    "    entities, sentiments = extract_stock_information(post.title)\n",
    "    if entities:\n",
    "        print(\"Entities: \", entities)\n",
    "        print(\"Sentiments: \", sentiments)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T12:23:24.671531622Z",
     "start_time": "2023-05-19T12:23:24.155667066Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "def retrieve_historical_stock_data(symbol, start_date, end_date):\n",
    "    stock_data = yf.download(symbol, start=start_date, end=end_date)\n",
    "    return stock_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T12:23:24.778603407Z",
     "start_time": "2023-05-19T12:23:24.675230007Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": "                  Open        High         Low       Close   Adj Close   \nDate                                                                     \n2023-04-03  199.910004  202.690002  192.199997  194.770004  194.770004  \\\n2023-04-04  197.320007  198.740005  190.320007  192.580002  192.580002   \n2023-04-05  190.520004  190.679993  183.759995  185.520004  185.520004   \n2023-04-06  183.080002  186.389999  179.740005  185.059998  185.059998   \n2023-04-10  179.940002  185.100006  176.110001  184.509995  184.509995   \n\n               Volume  \nDate                   \n2023-04-03  169545900  \n2023-04-04  126463800  \n2023-04-05  133882500  \n2023-04-06  123857900  \n2023-04-10  142154600  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2023-04-03</th>\n      <td>199.910004</td>\n      <td>202.690002</td>\n      <td>192.199997</td>\n      <td>194.770004</td>\n      <td>194.770004</td>\n      <td>169545900</td>\n    </tr>\n    <tr>\n      <th>2023-04-04</th>\n      <td>197.320007</td>\n      <td>198.740005</td>\n      <td>190.320007</td>\n      <td>192.580002</td>\n      <td>192.580002</td>\n      <td>126463800</td>\n    </tr>\n    <tr>\n      <th>2023-04-05</th>\n      <td>190.520004</td>\n      <td>190.679993</td>\n      <td>183.759995</td>\n      <td>185.520004</td>\n      <td>185.520004</td>\n      <td>133882500</td>\n    </tr>\n    <tr>\n      <th>2023-04-06</th>\n      <td>183.080002</td>\n      <td>186.389999</td>\n      <td>179.740005</td>\n      <td>185.059998</td>\n      <td>185.059998</td>\n      <td>123857900</td>\n    </tr>\n    <tr>\n      <th>2023-04-10</th>\n      <td>179.940002</td>\n      <td>185.100006</td>\n      <td>176.110001</td>\n      <td>184.509995</td>\n      <td>184.509995</td>\n      <td>142154600</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as datetime\n",
    "\n",
    "symbol = \"TSLA\"\n",
    "start_date = datetime.datetime(2023, 4, 1)\n",
    "end_date = datetime.datetime(2023, 5, 1)\n",
    "\n",
    "stock_data = retrieve_historical_stock_data(symbol, start_date, end_date)\n",
    "stock_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T12:23:25.180406985Z",
     "start_time": "2023-05-19T12:23:24.784212075Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               title   \n0  The state comptroller recommends that the MTA ...  \\\n1        Do opex days tend to be bullish or bearish?   \n2                             Volume tickers in play   \n3   Every regional bank Chief Risk Officer in 2023 :   \n4           Daily Discussion Thread for May 19, 2023   \n\n                                                body          date  score   \n0                                                     1.684500e+09      1  \\\n1  I'm trying to understand what opex means for m...  1.684500e+09      1   \n2  Trading Thesis: Tracking the float along with ...  1.684497e+09      2   \n3                                                     1.684495e+09      8   \n4  **Come hang out with us on the NEW WallStreetB...  1.684490e+09     29   \n\n         Date  \n0  2023-05-19  \n1  2023-05-19  \n2  2023-05-19  \n3  2023-05-19  \n4  2023-05-19  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>body</th>\n      <th>date</th>\n      <th>score</th>\n      <th>Date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The state comptroller recommends that the MTA ...</td>\n      <td></td>\n      <td>1.684500e+09</td>\n      <td>1</td>\n      <td>2023-05-19</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Do opex days tend to be bullish or bearish?</td>\n      <td>I'm trying to understand what opex means for m...</td>\n      <td>1.684500e+09</td>\n      <td>1</td>\n      <td>2023-05-19</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Volume tickers in play</td>\n      <td>Trading Thesis: Tracking the float along with ...</td>\n      <td>1.684497e+09</td>\n      <td>2</td>\n      <td>2023-05-19</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Every regional bank Chief Risk Officer in 2023 :</td>\n      <td></td>\n      <td>1.684495e+09</td>\n      <td>8</td>\n      <td>2023-05-19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Daily Discussion Thread for May 19, 2023</td>\n      <td>**Come hang out with us on the NEW WallStreetB...</td>\n      <td>1.684490e+09</td>\n      <td>29</td>\n      <td>2023-05-19</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = []\n",
    "\n",
    "for post in subreddit.new(limit = 100):\n",
    "    # if start_date.timestamp() <= post.created_utc <= end_date.timestamp():\n",
    "    posts.append({\n",
    "        'title': post.title,\n",
    "        'body': post.selftext,\n",
    "        'date': post.created_utc,\n",
    "        'score': post.score\n",
    "    })\n",
    "    # elif post.created_utc < start_date.timestamp():\n",
    "    #     break\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "posts_df = pd.DataFrame(posts)\n",
    "posts_df = posts_df.assign(Date = lambda x: datetime.fromtimestamp(x['date'][0]))\n",
    "posts_df = posts_df.assign(Date = lambda x: x['Date'][0].strftime(\"%Y-%m-%d\"))\n",
    "posts_df.drop()\n",
    "posts_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T12:47:30.503230854Z",
     "start_time": "2023-05-19T12:47:28.740367737Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def merge_data(posts, stock_data):\n",
    "    merged_data = pd.merge(posts, stock_data, how='inner', left_on='Date', right_index=True)\n",
    "    return merged_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T12:47:37.279370315Z",
     "start_time": "2023-05-19T12:47:37.278245966Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and datetime64[ns] columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[33], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m merged_data \u001B[38;5;241m=\u001B[39m \u001B[43mmerge_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mposts_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstock_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(merged_data)\n",
      "Cell \u001B[0;32mIn[32], line 2\u001B[0m, in \u001B[0;36mmerge_data\u001B[0;34m(posts, stock_data)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmerge_data\u001B[39m(posts, stock_data):\n\u001B[0;32m----> 2\u001B[0m     merged_data \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmerge\u001B[49m\u001B[43m(\u001B[49m\u001B[43mposts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstock_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minner\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mleft_on\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mDate\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m merged_data\n",
      "File \u001B[0;32m~/anaconda3/envs/tesla_forecast/lib/python3.10/site-packages/pandas/core/reshape/merge.py:144\u001B[0m, in \u001B[0;36mmerge\u001B[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;129m@Substitution\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mleft : DataFrame or named Series\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    128\u001B[0m \u001B[38;5;129m@Appender\u001B[39m(_merge_doc, indents\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    129\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmerge\u001B[39m(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    142\u001B[0m     validate: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    143\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame:\n\u001B[0;32m--> 144\u001B[0m     op \u001B[38;5;241m=\u001B[39m \u001B[43m_MergeOperation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    145\u001B[0m \u001B[43m        \u001B[49m\u001B[43mleft\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    146\u001B[0m \u001B[43m        \u001B[49m\u001B[43mright\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhow\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    148\u001B[0m \u001B[43m        \u001B[49m\u001B[43mon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mon\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[43m        \u001B[49m\u001B[43mleft_on\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mleft_on\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[43m        \u001B[49m\u001B[43mright_on\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mright_on\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[43m        \u001B[49m\u001B[43mleft_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mleft_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[43m        \u001B[49m\u001B[43mright_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mright_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[43m        \u001B[49m\u001B[43msort\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[43m        \u001B[49m\u001B[43msuffixes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msuffixes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindicator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindicator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    158\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m op\u001B[38;5;241m.\u001B[39mget_result(copy\u001B[38;5;241m=\u001B[39mcopy)\n",
      "File \u001B[0;32m~/anaconda3/envs/tesla_forecast/lib/python3.10/site-packages/pandas/core/reshape/merge.py:737\u001B[0m, in \u001B[0;36m_MergeOperation.__init__\u001B[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001B[0m\n\u001B[1;32m    729\u001B[0m (\n\u001B[1;32m    730\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mleft_join_keys,\n\u001B[1;32m    731\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mright_join_keys,\n\u001B[1;32m    732\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjoin_names,\n\u001B[1;32m    733\u001B[0m ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_merge_keys()\n\u001B[1;32m    735\u001B[0m \u001B[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001B[39;00m\n\u001B[1;32m    736\u001B[0m \u001B[38;5;66;03m# to avoid incompatible dtypes\u001B[39;00m\n\u001B[0;32m--> 737\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_coerce_merge_keys\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    739\u001B[0m \u001B[38;5;66;03m# If argument passed to validate,\u001B[39;00m\n\u001B[1;32m    740\u001B[0m \u001B[38;5;66;03m# check if columns specified as unique\u001B[39;00m\n\u001B[1;32m    741\u001B[0m \u001B[38;5;66;03m# are in fact unique.\u001B[39;00m\n\u001B[1;32m    742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m validate \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/tesla_forecast/lib/python3.10/site-packages/pandas/core/reshape/merge.py:1395\u001B[0m, in \u001B[0;36m_MergeOperation._maybe_coerce_merge_keys\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1393\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[1;32m   1394\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m needs_i8_conversion(lk\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mand\u001B[39;00m needs_i8_conversion(rk\u001B[38;5;241m.\u001B[39mdtype):\n\u001B[0;32m-> 1395\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[1;32m   1396\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(lk\u001B[38;5;241m.\u001B[39mdtype, DatetimeTZDtype) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[1;32m   1397\u001B[0m     rk\u001B[38;5;241m.\u001B[39mdtype, DatetimeTZDtype\n\u001B[1;32m   1398\u001B[0m ):\n\u001B[1;32m   1399\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n",
      "\u001B[0;31mValueError\u001B[0m: You are trying to merge on object and datetime64[ns] columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "merged_data = merge_data(posts_df, stock_data)\n",
    "print(merged_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T12:47:38.988275213Z",
     "start_time": "2023-05-19T12:47:38.880404807Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Assume merged_data contains the merged DataFrame with Reddit posts and stock price data\n",
    "# Ensure the DataFrame has columns for 'date', 'title', 'body', 'score', 'Open', 'Close', etc.\n",
    "\n",
    "# Prepare the features and target variables\n",
    "features = merged_data[['score', 'Open', 'Volume', 'Date']]  # Adjust the features based on your requirements\n",
    "target = merged_data['Close']  # Adjust the target variable based on your requirements\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "\n",
    "# Print the model performance\n",
    "print(\"Train Score:\", train_score)\n",
    "print(\"Test Score:\", test_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
